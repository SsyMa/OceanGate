\documentclass{article}

\PassOptionsToPackage{numbers, compress}{natbib}

\usepackage{nips_2016}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{titling}
\usepackage{graphicx}
\usepackage{placeins}


\title{Deep Learning Homework \\
  [1ex] Deep Learning Házi feladat \\
  \large Airbus Ship Detection Challenge}

\author{
  Nagy Dániel (UU5SCQ) \\
  Szénássy Márton (HIYXIQ) \\
  Varga-Labóczki Vazul (H947XW)
}


\begin{document}

\maketitle

\begin{abstract}
  This report presents our solution to the Airbus Ship Detection Challenge using a fully convolutional encoder–decoder architecture for ship segmentation in satellite images.
  We discuss our initial attempts with Segment Anything and the challenges we faced, leading us to adopt the FCN model.
  Our implementation includes various callbacks to enhance training, and we address challenges such as class imbalance through data augmentation.
  Overall, our solution demonstrates the effectiveness of deep learning techniques in addressing real-world problems in maritime surveillance.
\end{abstract}

\begin{kivonat}
  Ebben a dolgozatban bemutatjuk a megoldásunkat az Airbus Ship Detection Challenge kihívásra, amelyben FCN architektúrát alkalmaztunk a műholdfelvételeken megjelenő hajók szegmentálására.
  Ismertetjük kezdeti kísérleteinket a Segment Anything modellel, valamint azokat a kihívásokat, amelyekkel szembesültünk, és amelyek arra késztettek minket, hogy a FCN modellt válasszuk.
  Megvalósításunk különböző callback mechanizmusokat tartalmaz a tanulási folyamat javítása érdekében, és foglalkozunk olyan kihívásokkal, mint az osztályok közötti egyensúlyhiány, amelyet adat augmentációs technikákkal kezelünk.
  Összességében megoldásunk bemutatja a mélytanulási technikák hatékonyságát a tengeri megfigyelés valós problémáinak kezelésében.
\end{kivonat}

\tableofcontents

\section{Introduction}
This report presents our solution to the Airbus Ship Detection Challenge~\cite{airbus2018challenge}.
This challenge focuses on the task of detecting ships in satellite images using deep learning techniques~\cite{goodfellow2016deep, lecun1998gradient}.
The challenge addresses a real-world problem in maritime surveillance and ocean monitoring, where automated detection systems can significantly reduce manual labor and improve response times.
We solved this problem by developing a convolutional neural network-based segmentation model that accurately identifies ship locations in satellite imagery, drawing on recent advances in fully convolutional networks~\cite{long2015fcn}.

\section{Description of topic and previous solutions}
The Airbus Ship Detection Challenge is a competition hosted on the Kaggle platform, aiming to develop algorithms for detecting ships in satellite images.
The challenge provides a dataset of high-resolution satellite images, each annotated with masks indicating the presence and location of ships.
Participants are tasked with creating models that can accurately segment ships from the background in these images. \\
Previous solutions include various deep learning architectures, such as U-Net~\cite{ronneberger2015unet}, Mask R-CNN~\cite{he2017maskrcnn}, DeepLabv3+~\cite{chen2018deeplab}, and Segment Anything~\cite{kirillov2023sam}.
These models leverage convolutional neural networks (CNNs) to learn spatial hierarchies of features from the input images, often building on strong backbones like VGG~\cite{simonyan2014vgg}.
Many participants have also employed data augmentation techniques to enhance model robustness and improve generalization to unseen data~\cite{perez2017augmentation, shorten2019survey}.

\section{Architecture}
\subsection{First attempt}
Our initial approach involved implementing Segment Anything~\cite{kirillov2023sam}, a state-of-the-art segmentation model known for its versatility and performance across various segmentation tasks.
However, we encountered significant challenges during this phase due to the model's way of working.
Segment Anything is designed to generate segmentation masks based on user-provided prompts, such as points or bounding boxes.
This interactive nature made it difficult to adapt the model for fully automated ship detection in satellite images, as required by the challenge.
This made it impractical for our specific use case, leading us to explore alternative architectures better suited for automated segmentation tasks.

\subsection{Final model}
After evaluating various architectures, we implemented a fully convolutional network (FCN).
The chosen FCN is a simple encoder–decoder network composed exclusively of convolutional layers (no dense layers), with learned downsampling via strided convolutions and learned upsampling via transpose convolutions.
Unlike U-Net, this architecture does not use skip-connections between encoder and decoder paths.

\newpage

Key characteristics of our FCN:
\begin{itemize}
  \item Encoder: several Conv2D blocks with ReLU activations and BatchNormalization~\cite{ioffe2015batch}. Downsampling is performed using strided convolutions that reduce spatial resolution (e.g. 256 -> 128 -> 64 -> 32 -> 16).
  \item Decoder: Conv2DTranspose layers with ReLU activations and BatchNormalization~\cite{ioffe2015batch} to restore spatial resolution back to the input size.
  \item Classifier: a final Conv2D producing a single-channel output (kernel size 5, padding='same'). The model emits logits for binary segmentation; a sigmoid can be applied at loss/metric time.
  \item BatchNormalization is applied after each hidden convolutional layer to stabilize training.
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{Pictures/model.png}
    \caption{Model architecture (fully convolutional encoder–decoder).}
\end{figure}

\FloatBarrier

\subsubsection{Callbacks}
To enhance the training process and improve model performance, we incorporated several callbacks into our training routine:
\begin{itemize}
    \item \textbf{Model Checkpointing}: We used model checkpointing to save the best model weights based on validation loss during training. This ensures that we retain the most effective model configuration.
    \item \textbf{Early Stopping}: Early stopping was implemented to monitor the validation loss and halt training if no improvement was observed for a specified number of epochs. This helps prevent overfitting and reduces unnecessary computation.
    \item \textbf{Learning Rate Reduction}: We employed a learning rate reduction strategy that decreases the learning rate when the validation loss plateaus. This allows the model to fine-tune its weights more effectively during later stages of training.
\end{itemize}

\newpage

\section{Implementation}
\subsection{Training}
We trained our FCN model using the Adam optimizer~\cite{kingma2014adam} with a learning rate of 0.003 and a batch size of 32.
The training was conducted on our own hardware, utilizing a GPU to accelerate the training process.
The model was trained for 1000 epochs, with early stopping implemented to prevent overfitting.

\subsubsection{Preprocessing}
To enhance the model's performance, we incorporated data augmentation techniques during training, such as random rotations, flips, and zooms~\cite{perez2017augmentation, shorten2019survey}.
This is the main task of the preprocessing step, as it increases the diversity of the training data and helps prevent overfitting.
Additionally, we applied batch normalization~\cite{ioffe2015batch} to stabilize the training process.

\subsubsection{Problems}
During the training process, we encountered several challenges that required careful consideration and adjustments to our approach.
One of the primary issues was dealing with class imbalance in the dataset, as the number of pictures containing ships was significantly lower than the pictures without ships.
To address this, we implemented data augmentation techniques to increase the representation of ship-containing images in the training set.
The final ratio is 50-50 between images with and without ships.

\section{Summary}
In this report, we presented our approach to the Airbus Ship Detection Challenge using a fully convolutional encoder–decoder architecture for ship segmentation in satellite images.
We discussed our initial attempts with Segment Anything and the challenges we faced, leading us to adopt the FCN model.
Our implementation included various callbacks to enhance training, and we addressed challenges such as class imbalance through data augmentation.
Overall, our solution demonstrates the effectiveness of deep learning techniques in addressing real-world problems in maritime surveillance~\cite{long2015fcn, chen2018deeplab, zhou2018unetplusplus}.

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}
